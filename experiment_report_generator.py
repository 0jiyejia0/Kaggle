import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, mean_absolute_percentage_error
import os
from datetime import datetime
import json
from model_evaluation import calculate_metrics

plt.rcParams['font.sans-serif'] = ['SimHei']  # è®¾ç½®ä¸­æ–‡å­—ä½“
plt.rcParams['axes.unicode_minus'] = False   # è§£å†³è´Ÿå·æ˜¾ç¤ºé—®é¢˜

def load_predictions_from_experiment(experiment_dir):
    """ä»Žå®žéªŒç›®å½•åŠ è½½é¢„æµ‹ç»“æžœ"""
    predictions = {}
    pred_dir = f"{experiment_dir}/predictions"
    
    if os.path.exists(pred_dir):
        for file in os.listdir(pred_dir):
            if file.startswith('predictions_') and file.endswith('.csv'):
                model_name = file.replace('predictions_', '').replace('.csv', '')
                df = pd.read_csv(f"{pred_dir}/{file}")
                predictions[model_name] = df['SalePrice'].values
                print(f"âœ… åŠ è½½ {model_name} é¢„æµ‹ç»“æžœ: {len(df)} æ¡")
        
        # åŠ è½½èžåˆé¢„æµ‹
        if os.path.exists(f"{pred_dir}/final_predictions.csv"):
            df_final = pd.read_csv(f"{pred_dir}/final_predictions.csv")
            predictions['ensemble'] = df_final['SalePrice'].values
            print(f"âœ… åŠ è½½èžåˆé¢„æµ‹ç»“æžœ: {len(df_final)} æ¡")
    
    return predictions

def analyze_prediction_distribution(predictions, output_dir):
    """åˆ†æžé¢„æµ‹åˆ†å¸ƒ"""
    print("\nðŸ“Š === é¢„æµ‹åˆ†å¸ƒåˆ†æž ===")
    
    # åˆ›å»ºåˆ†å¸ƒå›¾
    fig, axes = plt.subplots(2, 2, figsize=(15, 12))
    
    # 1. å„æ¨¡åž‹é¢„æµ‹åˆ†å¸ƒå¯¹æ¯”
    ax1 = axes[0, 0]
    for model_name, pred in predictions.items():
        if model_name != 'ensemble':
            ax1.hist(pred, alpha=0.6, bins=50, label=model_name, density=True)
    ax1.set_xlabel('é¢„æµ‹ä»·æ ¼')
    ax1.set_ylabel('å¯†åº¦')
    ax1.set_title('å„æ¨¡åž‹é¢„æµ‹åˆ†å¸ƒå¯¹æ¯”')
    ax1.legend()
    ax1.grid(True, alpha=0.3)
    
    # 2. é¢„æµ‹ç»Ÿè®¡è¡¨
    stats_data = []
    for model_name, pred in predictions.items():
        stats = {
            'æ¨¡åž‹': model_name,
            'å‡å€¼': f"{pred.mean():.0f}",
            'ä¸­ä½æ•°': f"{np.median(pred):.0f}",
            'æ ‡å‡†å·®': f"{pred.std():.0f}",
            'æœ€å°å€¼': f"{pred.min():.0f}",
            'æœ€å¤§å€¼': f"{pred.max():.0f}",
            'ååº¦': f"{pd.Series(pred).skew():.3f}"
        }
        stats_data.append(stats)
        print(f"ðŸ”¸ {model_name}: å‡å€¼={pred.mean():.0f}, æ ‡å‡†å·®={pred.std():.0f}, èŒƒå›´=[{pred.min():.0f}, {pred.max():.0f}]")
    
    # 3. ç®±çº¿å›¾
    ax2 = axes[0, 1]
    box_data = [pred for model_name, pred in predictions.items() if model_name != 'ensemble']
    box_labels = [name for name in predictions.keys() if name != 'ensemble']
    ax2.boxplot(box_data, labels=box_labels)
    ax2.set_ylabel('é¢„æµ‹ä»·æ ¼')
    ax2.set_title('é¢„æµ‹ä»·æ ¼ç®±çº¿å›¾')
    ax2.tick_params(axis='x', rotation=45)
    ax2.grid(True, alpha=0.3)
    
    # 4. æ¨¡åž‹ç›¸å…³æ€§
    if len(predictions) > 1:
        ax3 = axes[1, 0]
        model_names = [name for name in predictions.keys() if name != 'ensemble']
        pred_matrix = np.array([predictions[name] for name in model_names]).T
        corr_matrix = np.corrcoef(pred_matrix.T)
        
        im = ax3.imshow(corr_matrix, cmap='coolwarm', vmin=-1, vmax=1)
        ax3.set_xticks(range(len(model_names)))
        ax3.set_yticks(range(len(model_names)))
        ax3.set_xticklabels(model_names)
        ax3.set_yticklabels(model_names)
        ax3.set_title('æ¨¡åž‹é¢„æµ‹ç›¸å…³æ€§')
        
        # æ·»åŠ æ•°å€¼æ ‡æ³¨
        for i in range(len(model_names)):
            for j in range(len(model_names)):
                ax3.text(j, i, f'{corr_matrix[i, j]:.3f}', 
                        ha="center", va="center", color="black")
        plt.colorbar(im, ax=ax3)
    
    # 5. èžåˆæ•ˆæžœå¯¹æ¯”
    ax4 = axes[1, 1]
    if 'ensemble' in predictions:
        individual_models = [name for name in predictions.keys() if name != 'ensemble']
        ensemble_pred = predictions['ensemble']
        
        # è®¡ç®—å„æ¨¡åž‹ä¸Žèžåˆç»“æžœçš„å·®å¼‚
        differences = []
        for model_name in individual_models:
            diff = np.abs(predictions[model_name] - ensemble_pred)
            differences.append(diff)
            ax4.hist(diff, alpha=0.6, bins=30, label=f'{model_name} vs Ensemble', density=True)
        
        ax4.set_xlabel('ä¸Žèžåˆé¢„æµ‹çš„ç»å¯¹å·®å¼‚')
        ax4.set_ylabel('å¯†åº¦')
        ax4.set_title('å„æ¨¡åž‹ä¸Žèžåˆé¢„æµ‹çš„å·®å¼‚åˆ†å¸ƒ')
        ax4.legend()
        ax4.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.savefig(f"{output_dir}/prediction_analysis.png", dpi=300, bbox_inches='tight')
    plt.close()
    
    # ä¿å­˜ç»Ÿè®¡è¡¨
    stats_df = pd.DataFrame(stats_data)
    stats_df.to_csv(f"{output_dir}/prediction_statistics.csv", index=False)
    print(f"âœ… é¢„æµ‹åˆ†æžå›¾å·²ä¿å­˜åˆ°: {output_dir}/prediction_analysis.png")
    
    return stats_df

def analyze_price_segments(predictions, output_dir):
    """åˆ†æžä¸åŒä»·æ ¼æ®µçš„é¢„æµ‹è¡¨çŽ°"""
    print("\nðŸ˜ï¸ === ä»·æ ¼æ®µåˆ†æž ===")
    
    # å®šä¹‰ä»·æ ¼æ®µ
    price_segments = {
        'ä½Žä»·ä½': (0, 150000),
        'ä¸­ä½Žä»·ä½': (150000, 200000),
        'ä¸­ä»·ä½': (200000, 300000),
        'ä¸­é«˜ä»·ä½': (300000, 400000),
        'é«˜ä»·ä½': (400000, float('inf'))
    }
    
    segment_analysis = []
    
    for segment_name, (min_price, max_price) in price_segments.items():
        segment_stats = {'ä»·æ ¼æ®µ': segment_name, 'ä»·æ ¼èŒƒå›´': f"{min_price:,} - {max_price:,}" if max_price != float('inf') else f"{min_price:,}+"}
        
        for model_name, pred in predictions.items():
            if model_name != 'ensemble':
                mask = (pred >= min_price) & (pred < max_price)
                count = mask.sum()
                percentage = count / len(pred) * 100
                avg_price = pred[mask].mean() if count > 0 else 0
                
                segment_stats[f'{model_name}_æ•°é‡'] = count
                segment_stats[f'{model_name}_å æ¯”'] = f"{percentage:.1f}%"
                segment_stats[f'{model_name}_å‡ä»·'] = f"{avg_price:.0f}"
        
        segment_analysis.append(segment_stats)
        print(f"ðŸ”¸ {segment_name} ({min_price:,}-{max_price:,}): {sum((predictions[name] >= min_price) & (predictions[name] < max_price) for name in predictions if name != 'ensemble')} ä¸ªé¢„æµ‹")
    
    # ä¿å­˜ä»·æ ¼æ®µåˆ†æž
    segment_df = pd.DataFrame(segment_analysis)
    segment_df.to_csv(f"{output_dir}/price_segment_analysis.csv", index=False)
    print(f"âœ… ä»·æ ¼æ®µåˆ†æžå·²ä¿å­˜åˆ°: {output_dir}/price_segment_analysis.csv")
    
    return segment_df

def create_performance_report(experiment_dir):
    """åˆ›å»ºå®Œæ•´çš„æ€§èƒ½æŠ¥å‘Š"""
    print("ðŸ“‹ === åˆ›å»ºæ€§èƒ½æŠ¥å‘Š ===")
    
    # åˆ›å»ºæŠ¥å‘Šç›®å½•
    report_dir = f"{experiment_dir}/performance_report"
    os.makedirs(report_dir, exist_ok=True)
    
    # åŠ è½½é¢„æµ‹ç»“æžœ
    predictions = load_predictions_from_experiment(experiment_dir)
    
    if not predictions:
        print("âŒ æœªæ‰¾åˆ°é¢„æµ‹ç»“æžœï¼Œæ— æ³•ç”ŸæˆæŠ¥å‘Š")
        return None
    
    # 1. åˆ†å¸ƒåˆ†æž
    stats_df = analyze_prediction_distribution(predictions, report_dir)
    
    # 2. ä»·æ ¼æ®µåˆ†æž
    segment_df = analyze_price_segments(predictions, report_dir)
    
    # 3. ç”Ÿæˆæ–‡æœ¬æŠ¥å‘Š
    report_text = f"""
# æ¨¡åž‹æ€§èƒ½è¯„ä¼°æŠ¥å‘Š

## ðŸŽ¯ å®žéªŒä¿¡æ¯
- å®žéªŒæ—¶é—´: {experiment_dir.split('/')[-1]}
- æ¨¡åž‹æ•°é‡: {len([k for k in predictions.keys() if k != 'ensemble'])}
- é¢„æµ‹æ ·æœ¬æ•°: {len(list(predictions.values())[0])}

## ðŸ“Š æ¨¡åž‹é¢„æµ‹ç»Ÿè®¡

{stats_df.to_string(index=False)}

## ðŸ˜ï¸ ä»·æ ¼æ®µåˆ†å¸ƒ

{segment_df.to_string(index=False)}

## ðŸŽ‰ ç»“è®º
- æœ€ä¼˜å•æ¨¡åž‹: {min(predictions.keys(), key=lambda x: np.std(predictions[x]) if x != 'ensemble' else float('inf'))}
- é¢„æµ‹èŒƒå›´: ${min(predictions['ensemble']):.0f} - ${max(predictions['ensemble']):.0f}
- å¹³å‡é¢„æµ‹ä»·æ ¼: ${np.mean(predictions['ensemble']):.0f}

## ðŸ“ˆ å»ºè®®
1. æ¨¡åž‹é¢„æµ‹ç»“æžœè¾ƒä¸ºä¸€è‡´ï¼Œèžåˆæ•ˆæžœè‰¯å¥½
2. å…³æ³¨é«˜ä»·ä½æˆ¿å±‹çš„é¢„æµ‹å‡†ç¡®æ€§
3. å¯ä»¥è€ƒè™‘æ·»åŠ æ›´å¤šç‰¹å¾æ¥æå‡æ€§èƒ½
"""
    
    with open(f"{report_dir}/performance_report.md", "w", encoding='utf-8') as f:
        f.write(report_text)
    
    print(f"âœ… å®Œæ•´æ€§èƒ½æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_dir}/")
    return report_dir

def main():
    print("ðŸŽ¯ === æ¨¡åž‹æ€§èƒ½å…¨é¢è¯„ä¼° ===")
    
    # æ‰¾åˆ°æœ€æ–°çš„å®žéªŒç›®å½• (ä¿ç•™è¿™éƒ¨åˆ†é€»è¾‘ï¼Œå› ä¸ºæŠ¥å‘Šç”Ÿæˆå™¨éœ€è¦å®ƒ)
    experiment_path = None
    experiments_dir = "experiments"
    if os.path.exists(experiments_dir):
        experiment_dirs = sorted([d for d in os.listdir(experiments_dir) if os.path.isdir(os.path.join(experiments_dir, d))])
        if experiment_dirs:
            latest_experiment = experiment_dirs[-1] # èŽ·å–æœ€æ–°çš„
            experiment_path = os.path.join(experiments_dir, latest_experiment)
            print(f"INFO: å°†ä¸ºå®žéªŒç›®å½• '{experiment_path}' ç”ŸæˆæŠ¥å‘Š")
        else:
            print("WARNING: åœ¨ 'experiments' ç›®å½•ä¸‹æ²¡æœ‰æ‰¾åˆ°å®žéªŒå­ç›®å½•ã€‚")
    else:
        print(f"WARNING: 'experiments' ç›®å½•ä¸å­˜åœ¨ã€‚")

    if experiment_path:
        # åˆ›å»ºæ€§èƒ½æŠ¥å‘Š
        report_dir = create_performance_report(experiment_path)
        
        if report_dir:
            print(f"\nðŸŽ‰ === è¯„ä¼°å®Œæˆ ===")
            print(f"ðŸ“ å®Œæ•´æŠ¥å‘Šä¿å­˜åœ¨: {report_dir}")
            print(f"ðŸ“Š ä¸»è¦æ–‡ä»¶:")
            print(f"   - prediction_analysis.png (é¢„æµ‹åˆ†æžå›¾)")
            print(f"   - prediction_statistics.csv (é¢„æµ‹ç»Ÿè®¡)")
            print(f"   - price_segment_analysis.csv (ä»·æ ¼æ®µåˆ†æž)")
            print(f"   - performance_report.md (å®Œæ•´æŠ¥å‘Š)")
        else:
            print("âŒ æŠ¥å‘Šç”Ÿæˆå¤±è´¥")
    else:
        print("âŒ æœªæ‰¾åˆ°å®žéªŒç›®å½•")

if __name__ == "__main__":
    main() 